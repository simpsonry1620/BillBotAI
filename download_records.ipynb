{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Appropriations Bill Scraper\n","This notebook downloads the appropriations bill from the US Congress website, then extracts the raw text from the html files.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Import Libraries\n","from bs4 import BeautifulSoup\n","import os\n","import requests"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Download a file at the given url and save to output path\n","def download_file(url, output_path):\n","    \n","    # Send a GET request to the URL\n","    response = requests.get(url)\n","    \n","    # Check if the request was successful (HTTP status code 200)\n","    if response.status_code == 200:\n","        # Ensure the directory exists (optional, but recommended)\n","        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n","        \n","        # Open the file with write-binary mode and write the contents of the response\n","        with open(output_path, 'wb') as file:\n","            file.write(response.content)\n","    else:\n","        print(f\"Failed to download {url}\")\n","\n","# Download the HTML files\n","def download_html_files():\n","\n","    # Base URL\n","    base_url = \"https://www.govinfo.gov/content/pkg/\"\n","\n","    # Create a directory to store the HTML files\n","    os.makedirs('html_files', exist_ok=True)\n","    \n","    # Download the HTML files\n","    for i in range(1, 42):\n","        \n","        url = base_url + f\"USCODE-2022-title{i}/html/USCODE-2022-title{i}.htm\"\n","        output_path = f'html_files/USCODE-2022-title{i}.htm'\n","        \n","        print(f\"Downloading {url}...\")\n","        download_file(url, output_path)\n","\n","# Function to extract text\n","def extract_text_from_html(file_path):\n","    with open(file_path, 'r', encoding='utf-8') as file:\n","        html_content = file.read()\n","        \n","    soup = BeautifulSoup(html_content, 'html.parser')\n","    \n","    # Remove script and style elements\n","    for script_or_style in soup([\"script\", \"style\"]):\n","        script_or_style.decompose()\n","    \n","    # Get text\n","    text = soup.get_text()\n","    \n","    # Break into lines and remove leading and trailing space on each\n","    lines = (line.strip() for line in text.splitlines())\n","    # Break multi-headlines into a line each\n","    chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n","    # Drop blank lines\n","    text = '\\n'.join(chunk for chunk in chunks if chunk)\n","    \n","    return text\n","\n","# Extract text from the HTML files\n","def extract_text_from_html_files():\n","    # Create a directory to store the text files\n","    os.makedirs('text_files', exist_ok=True)\n","    \n","    # Extract text from the HTML files\n","    for i in range(1, 42):\n","        file_path = f'html_files/USCODE-2022-title{i}.htm'\n","        text = extract_text_from_html(file_path)\n","        with open(f'text_files/USCODE-2022-title{i}.txt', 'w', encoding='utf-8') as file:\n","            file.write(text)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Download the HTML files\n","download_html_files()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Extract the raw text from the HTML files\n","extract_text_from_html_files()"]}],"metadata":{"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":2}
